<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="UTF-8">
	<title>Five-Billion-Pixels Dataset</title>
	<link type="text/css" href="/project/head/system.css" rel="stylesheet"/>
	<link type="text/css" href="/project/head/custom.css" rel="stylesheet"/>
	<script type="text/javascript" src="/project/head/custom.js"></script>
</head>

<body marginheight="0">
<div align="center"><h1>Enabling Country-Scale Land Cover Mapping with <br> Meter-Resolution Satellite Imagery</h1></div>

<p style="text-align: center">Xin-Yi Tong, Gui-Song Xia, Xiao Xiang Zhu</p>

<h2>Introduction</h2>
<p>High-resolution satellite images can provide abundant, detailed spatial information for land cover classification, which is particularly 
important for studying the complicated environment of human activity areas. However, due to the complex land cover patterns, the costly 
training sample collections, and the severe distribution shifts of satellite imageries caused by, e.g., geographical differences or acquisition 
conditions, few studies have applied high-resolution images to land cover mapping in detailed categories at large scale. To fill this gap, we 
present a large-scale land cover dataset, <b>Five-Billion-Pixels</b>. It contains more than 5 billion labeled pixels of 150 high-resolution 
Gaofen-2 (4 m) satellite images, annotated in a 24-category system covering artificial-constructed, agricultural, and natural classes. In the 
meantime, we propose a deep-learning-based unsupervised domain adaptation approach that can transfer classification models trained on labeled 
dataset (referred to as the source domain) to unlabeled data (referred to as the target domain) for large-scale land cover mapping. Specifically, 
we introduce an end-to-end Siamese network employing dynamic pseudo-label assignment and class balancing strategy to perform adaptive domain 
joint learning. To validate the generality of our dataset and approach across different satellite imageries, we implement land cover mapping 
on five Chinese megacities severally using: PlanetScope (3 m), Gaofen-1 (8 m), and Sentinel-2 (10 m) satellite images. Over a total study area of 
53,088 square kilometers, the experiments show promising results even though the input images are entirely unlabeled. The proposed approach, 
trained with the <b>Five-Billion-Pixels</b> dataset, enables high-quality and detailed land cover mapping across the whole country of China at 
meter-resolution.</p>

<h3>Five-Billion-Pixels</h3>
<p>We present a large-scale land cover classification dataset, <b>Five-Billion-Pixels</b>. It has a spatial resolution of <b>4 m</b>, covers areas 
more than <b>50,000 square kilometers</b> in China, and contains more than <b>5 billion</b> labeled pixels. It possesses the advantage of rich 
categories, large coverage, wide distribution, and high-spatial resolution, which well reflects the distributions of real-world ground objects and 
can benefit to different land cover related studies.</p>

<div style="border: 9px solid #FFFFFF"></div>
<div id = "tab1" class = "tabMenu">
	<ul>
	<li class="on"><h4>Distribution and Categories</h4></li>
        <li class="off"><h4>Annotation Details</h4></li>
        <li class="off"><h4>Download</h4></li>
        </ul>
	<div id="firstPage" class="show">
	<img src="/figure/GID24/GID24example.png" width="800px">
        </div>
        <div id="secondPage" class= "hide">
	<p style="margin-top: 5px"><b>Five-Billion-Pixels</b> extends <a href="https://x-ytong.github.io/project/GID.html"><b>GID</b></a> 
	and <a href="https://captain-whu.github.io/HPS-Net/"><b>GID-15</b></a>. Every label map has been carefully amended and expanded.</p>
        <img src="/figure/GID24/GID24detail.png" width="800px">
        </div>
        <div id="thirdPage" class = "hide">
        <p style="margin-top: 5px"><b>Five-Billion-Pixels</b> can be download from Onedrive or Baidudrive:</p>
        <li style="margin-top: 5px" class = "dot"><span class = "lin">Link: <a href="https://whueducn-my.sharepoint.com/:f:/g/personal/xinyi_tong_whu_edu_cn/EodxwsN54_5Ph0LAMROBi9sBWPzgCYAbBW-LK75qcrOG8w"><b>Onedrive</b></a></span></li>
        <li style="margin-top: 5px" class = "dot"><span class = "lin">Link: <a href="https://pan.baidu.com/s/1CX-qH8WQdSfQV7AspeHXeA"><b>Baidudrive</b></a>(extraction code: FBPS)</span></li>
        </div>
</div>
<div style="border: 9px solid #FFFFFF"></div>
		
<h3>Land Cover Mapping</h3>
<p> We propose an unsupervised domain adaptation approach for large-scale land cover mapping. Specifically, we introduce an end-to-end siamese 
network consisting of two branches, which separately process images from the source and target domain. In the target domain branch, image pixels 
with high-confidence are assigned with pseudo-labels and then utilized for domain joint learning with the source domain branch. To mitigate 
negative adaptation, we adopt dynamic pseudo-label assignment and class balancing strategy in the network. We achieve land cover mapping on 5 
Chinese megacities using various satellite images: <b>PlanetScope (PS)</b> images are used for Chengdu and Shanghai, <b>Gaofen-1 (GF-1)</b> 
images are used for Wuhan, <b>Sentinel-2 (ST-2)</b> images are used for Beijing and Guangzhou. The encouraging results show the generality of 
our dataset and approach across different satellites and regions.</p>

<div style="border: 9px solid #FFFFFF"></div>
<div id = "tab2" class = "tabMenu">
	<ul>
	<li class="on"><h4>Overview of Approach</h4></li>
        <li class="off"><h4>Study Areas</h4></li>
        <li class="off"><h4>Code</h4></li>
        </ul>
	<div id="firstPage" class="show">
	<table align="center"><tr>
	<td><img src="/figure/GID24/GID24siamesenetwork.png" style="height:188.6px"></td>
	<td><img src="/figure/GID24/GID24pseudolabel.png" style="height:188.6px"></td>
	</tr></table>
        </div>
        <div id="secondPage" class= "hide">
	<img src="/figure/GID24/GID24studyarea.png" width="800px">
        </div>
        <div id="thirdPage" class = "hide">
        <li style="margin-top: 5px" class = "dot"><span class = "lin">Link: <a href=" "><b>Coming Soon</b></a> </span></li>
        </div>
</div>
<div style="border: 9px solid #FFFFFF"></div>

<h4 class = "bar">Result Demonstration</h4>
<p style="margin-top: 18px"> Due to the large size of resulting maps, only the central area of each city is shown.</p>
	<hr></hr> 
	<table align="center"><tr>
	<td style="text-align:center"><a href="https://x-ytong.github.io/project/page/Five-Billion-Pixels_beijing.html">  <img src="/figure/GID24/GID24beijingsmall.png"   style="height:168px"></a> <br> Beijing   </td>
	<td style="text-align:center"><a href="https://x-ytong.github.io/project/page/Five-Billion-Pixels_chengdu.html">  <img src="/figure/GID24/GID24chengdusmall.png"   style="height:168px"></a> <br> Chengdu   </td>
	<td style="text-align:center"><a href="https://x-ytong.github.io/project/page/Five-Billion-Pixels_guangzhou.html"><img src="/figure/GID24/GID24guangzhousmall.png" style="height:168px"></a> <br> Guangzhou </td>
	<td style="text-align:center"><a href="https://x-ytong.github.io/project/page/Five-Billion-Pixels_shanghai.html"> <img src="/figure/GID24/GID24shanghaismall.png"  style="height:168px"></a> <br> Shanghai  </td>
	<td style="text-align:center"><a href="https://x-ytong.github.io/project/page/Five-Billion-Pixels_wuhan.html">    <img src="/figure/GID24/GID24wuhansmall.png"     style="height:168px"></a> <br> Wuhan     </td>
	</tr></table>
	<hr></hr>  
<div style="border: 9px solid #FFFFFF"></div>

<h3>Citation</h3>
<pre>
@article   { ,
 title   = { },
 author  = { },
 journal = { },
 year    = { }
}
</pre>

<h3>Contact</h3>
<p>E-mail: xinyi.tong@dlr.de</p>
<p>Personal page: <a href="https://x-ytong.github.io/index.html"><b>Xin-Yi Tong</b></a></p>

<div style="border:40px solid #FFFFFF"></div>


</body>
</html>
